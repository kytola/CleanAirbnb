{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Stage Panel Data Cleaning\n",
    "\n",
    "This notebook performs the first round of data cleaning tasks on the final long form data produced from the aggregate data notebook. These tasks include creating leads and lags, general formatting, filling N/A values, and identifying missing neighborhoods. It then saves the cleaned data into a compressed csv.gz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import operator # This allows one to pass operators into a Python function\n",
    "import mpu # For distance calculation\n",
    "from scipy import stats # Used to find modal value of geographic values\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_per_mi = 1.60934 #for conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal directory setup\n",
    "cwd1 = os.getcwd() \n",
    "\n",
    "# Go up one directory level\n",
    "os.chdir('..')\n",
    "cwd2 = os.getcwd()\n",
    "\n",
    "# Make sure repository has a 2. Clean data and Saved data folders!\n",
    "csv_raw_path = cwd2 + '/1. Download and compile data/'\n",
    "csv_save_path = cwd2 + '/2. Clean data/'\n",
    "\n",
    "# Revert to preliminary directory\n",
    "os.chdir(cwd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read concatenated data\n",
    "os.chdir(csv_raw_path)\n",
    "\n",
    "listings_df = pd.read_csv('Data_longALL_v1.csv.gz', low_memory=False)\n",
    "listings_df = listings_df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Switch to other folder for saving data\n",
    "os.chdir(csv_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destringing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destring_price(var):\n",
    "    \"\"\"\n",
    "    Destrings a passed variable.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = listings_df[var].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "for var in ['price', 'weekly_price', 'monthly_price', 'security_deposit', 'cleaning_fee', 'extra_people']:\n",
    "    destring_price(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dates(var):\n",
    "    \"\"\"\n",
    "    This function converts date variables into datetime format.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = pd.to_datetime(listings_df[var])\n",
    "    \n",
    "# ===============================================================    \n",
    "\n",
    "def dates_diff(var_name, var1, var2):\n",
    "    \"\"\"\n",
    "    Computes the difference between two date variables and assigns\n",
    "    the difference to a new variable of given name.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var_name] = listings_df[var1] - listings_df[var2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop of date formatting\n",
    "for date_vars in ['last_scraped', 'host_since', 'first_review', 'last_review']:\n",
    "    format_dates(date_vars)\n",
    "    \n",
    "# Set the 'scrape_batch' as a modal date for a file being scraped in a CSV\n",
    "\n",
    "for m in listings_df['month'].unique():\n",
    "    listings_df.loc[listings_df['month'] == m, 'scrape_batch'] = listings_df[listings_df['month'] == m]['last_scraped'].mode().values[0]\n",
    "    listings_df.loc[:, 'scrape_batch'] = pd.to_datetime(listings_df['scrape_batch'])\n",
    "    \n",
    "# Create a YR, MO value for the scrape batch, this is largely used for graphing where one needs to aggregate by year-month\n",
    "listings_df.loc[:,\"batch_YRMO\"] = pd.to_datetime(listings_df['scrape_batch']).dt.to_period('M')    \n",
    "\n",
    "# Calculate different date differences\n",
    "dates_diff('days_since_rev', 'last_scraped', 'last_review')\n",
    "dates_diff('days_since_first_rev', 'last_scraped', 'first_review')\n",
    "dates_diff('host_length', 'last_scraped', 'host_since')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leads and lag creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natfern/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "def create_lagsleads(var, lag_range, df, title):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function creates lag variables within a given range \n",
    "    for a given variable within a given dataframe. The title of these lag \n",
    "    variables is specified by title.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.sort_values(by = ['id', 'month'])\n",
    "    \n",
    "    for i in range(-lag_range, lag_range + 1):\n",
    "        \n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        if i < 0:\n",
    "            df.loc[:, title + \"lead\" + str(abs(i)) ] = df.groupby('id')[var].shift(i)\n",
    "                \n",
    "        if i > 0: \n",
    "            df.loc[:, title + \"lag\" + str(abs(i)) ] = df.groupby('id')[var].shift(i)\n",
    "            \n",
    "    return df\n",
    "\n",
    "listings_df = create_lagsleads('List_month', 12, listings_df, \"List\") # This would be much faster in numpy...\n",
    "listings_df = create_lagsleads('availability_60', 12, listings_df, \"avail60\")\n",
    "listings_df = create_lagsleads('availability_90', 12, listings_df, \"avail90\")\n",
    "listings_df = create_lagsleads('availability_365', 12, listings_df, \"avail365\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating a cleaned version of changes in the number of reviews a property has.\n",
    "\n",
    "listings_df = listings_df.reset_index(drop=True)\n",
    "\n",
    "listings_df.loc[:, 'max_lag'] = listings_df.groupby(['id'])['number_of_reviews'].rolling(4).max().reset_index(level=0, drop=True)\n",
    "listings_df['max_lag'].fillna(listings_df['number_of_reviews'], inplace=True)\n",
    "listings_df.loc[:, 'fixed_lag'] = listings_df.groupby('id')['max_lag'].shift(1)\n",
    "listings_df.loc[:, \"NOR_diff\"] = listings_df['max_lag'] - listings_df['fixed_lag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_missing_data(var):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function checks what the difference between the number of unique ids and the \n",
    "    number of ids paired with some property characteristic. \n",
    "    The key use case is to see whether or not a listing trait changes.\n",
    "    \"\"\"\n",
    "    \n",
    "    ids = listings_df[['id']].drop_duplicates().dropna()\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    paired_ids = listings_df[['id', var]].dropna().drop_duplicates()\n",
    "    paired_ids = np.array(paired_ids)\n",
    "    \n",
    "    if len(ids) == len(paired_ids):\n",
    "        print('No change in variable')\n",
    "    else:\n",
    "        print(\"Variable changes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_variable_changes(var, cutoff, relate, df):\n",
    "    \"\"\"\n",
    "    This function lists ids where the variable of interest changes (\"var\").\n",
    "    \"\"\"\n",
    "    ops = {'>': operator.gt,\n",
    "       '<': operator.lt,\n",
    "       '>=': operator.ge,\n",
    "       '<=': operator.le,\n",
    "       '==': operator.eq}\n",
    "    \n",
    "    # Take ids and variable of interest and drop any na's\n",
    "    repetition_arr = np.array(df[['id', var]].dropna().drop_duplicates()) # Need drop_duplicates to identify actual price changes\n",
    "    counts = np.unique(repetition_arr[:,0], return_counts = True)\n",
    "    return counts[0][ops[relate](counts[1], cutoff)], counts[1][ops[relate](counts[1], cutoff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172901           NaN\n",
       "172902           NaN\n",
       "172903           NaN\n",
       "172904           NaN\n",
       "172905           NaN\n",
       "172906   -122.642496\n",
       "172907   -122.641794\n",
       "172908   -122.641059\n",
       "172909   -122.640360\n",
       "172910   -122.638926\n",
       "Name: longitude, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of a listing where longitude changes at least 7 times\n",
    "\n",
    "change_vars, change_counts = identify_variable_changes('longitude', 7, \">=\", listings_df)\n",
    "listings_df[listings_df['id']==change_vars[0]]['longitude'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling in N/A's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the code fills missing data in forwards and backwards for values that would be expected to be invariant over time, such as fixed property features, and host characteristics, such as when the host first started using Airbnb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the modal zip codes as a property's zip code\n",
    "modal_zips = listings_df.groupby('id')['zipcode'].agg(lambda x: stats.mode(x)[0][0])\n",
    "listings_df.loc[:, 'zipcode'] = modal_zips[listings_df['id']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption: Properties do not change features when they are no observed\n",
    "Forward fill, then back fill. This means older properties have priority. This is an assumption! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes to run filling loop:\n",
      "0.5230273365974426\n"
     ]
    }
   ],
   "source": [
    "# Run a loop that fills property characteristics forwards and backwards\n",
    "\n",
    "my_timer = time.time() # Time it\n",
    "\n",
    "for var in ['host_id', 'host_name', 'host_since', 'host_location', 'property_type', 'room_type', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'first_review', 'instant_bookable']:\n",
    "    listings_df.loc[:, var] = listings_df.groupby(['id'])[var].fillna(method='ffill', axis=0)\n",
    "    listings_df.loc[:, var] = listings_df.groupby(['id'])[var].fillna(method='bfill', axis=0)\n",
    "    \n",
    "time_to_run_filler =  time.time() - my_timer\n",
    "\n",
    "print(\"Minutes to run filling loop:\")\n",
    "print(time_to_run_filler/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(var):\n",
    "    \"\"\"\n",
    "    Creates a dummy variable for a given variable\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = listings_df[var].astype('category')\n",
    "    listings_df.loc[:, var + \"_dum\"] = listings_df[var].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dummy variables for specified categories\n",
    "\n",
    "categorical_vars = ['host_is_superhost', 'room_type', 'instant_bookable', 'zipcode']\n",
    "\n",
    "for cat in categorical_vars:\n",
    "    create_dummies(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood categorization\n",
    "This section assigns each property to a specific neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding appropriate neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total listings:\n",
      "418359\n",
      "-------------------------\n",
      "Active listings with neighborhood reported:\n",
      "140237\n",
      "-------------------------\n",
      "Active listings with no neighborhood reported:\n",
      "10201\n"
     ]
    }
   ],
   "source": [
    "# How many total listings there are\n",
    "\n",
    "print(\"Total listings:\")\n",
    "\n",
    "print(len(listings_df['neighbourhood'].astype('category')))\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Active listings with neighborhood reported:\")\n",
    "print(len(listings_df[(listings_df['List_month']==1) & (~listings_df['neighbourhood'].isna())]))\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Active listings with no neighborhood reported:\")\n",
    "print(len(listings_df[(listings_df['List_month']==1) & (listings_df['neighbourhood'].isna())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code replaces each listing's neighborhood with its modal neighborhood\n",
    "modal_neighs = listings_df.groupby('id')['neighbourhood'].agg(lambda x: stats.mode(x)[0][0])\n",
    "listings_df.loc[:, 'neighbourhood'] = modal_neighs[listings_df['id']].values\n",
    "\n",
    "# Creates a dummy for whether neighborhood was initially reported\n",
    "listings_df.loc[:, 'missing_neigh'] = (listings_df['neighbourhood'] == 0)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average the reported longitude and latitude\n",
    "The longitude and latitude of a given property sometimes changes due to anonymization of Airbnb exact location. Since I am looking to assign a given property to a neighborhood, I just average these longitudes and latitudes to determine a representative location. This approach should be reasonable as long as anonymization is close to random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_avg_lat, id_avg_lon = listings_df.groupby('id')['latitude'].mean(), listings_df.groupby('id')['longitude'].mean()\n",
    "\n",
    "listings_df.loc[:,'avg_lat'] = np.array(id_avg_lat[(listings_df['id'].values)])\n",
    "listings_df.loc[:, 'avg_lon'] = np.array(id_avg_lon[(listings_df['id'].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>avg_lat</th>\n",
       "      <th>avg_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1324</td>\n",
       "      <td>67036</td>\n",
       "      <td>45.531952</td>\n",
       "      <td>-122.644825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2109</td>\n",
       "      <td>107177</td>\n",
       "      <td>45.496996</td>\n",
       "      <td>-122.745876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4516</td>\n",
       "      <td>246398</td>\n",
       "      <td>45.479189</td>\n",
       "      <td>-122.607044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5322</td>\n",
       "      <td>281285</td>\n",
       "      <td>45.532832</td>\n",
       "      <td>-122.705484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11027</td>\n",
       "      <td>668224</td>\n",
       "      <td>45.532556</td>\n",
       "      <td>-122.777067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id    avg_lat     avg_lon\n",
       "0   1324   67036  45.531952 -122.644825\n",
       "1   2109  107177  45.496996 -122.745876\n",
       "2   4516  246398  45.479189 -122.607044\n",
       "3   5322  281285  45.532832 -122.705484\n",
       "4  11027  668224  45.532556 -122.777067"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set-up a dataframe of all of the listings missing a neighborhood\n",
    "missing_neigh = listings_df[(listings_df['List_month'] == 1) & (listings_df['neighbourhood'] == 0) & (~listings_df['latitude'].isna()) & (~listings_df['longitude'].isna())][['id', 'avg_lat', 'avg_lon']]\n",
    "missing_neigh = missing_neigh.drop_duplicates()\n",
    "missing_neigh = missing_neigh.sort_index()\n",
    "missing_neigh = missing_neigh.reset_index(drop = False)\n",
    "\n",
    "# Dataframe of all the listings, that are not missing a neighborhood\n",
    "not_missing_neigh = listings_df[(listings_df['List_month'] == 1) & (listings_df['neighbourhood'] != 0) & (~listings_df['latitude'].isna()) & (~listings_df['longitude'].isna())][['id', 'neighbourhood','avg_lat', 'avg_lon']]\n",
    "not_missing_neigh = not_missing_neigh.drop_duplicates()\n",
    "\n",
    "# Print first five rows of the missing neighborhood dataframe\n",
    "missing_neigh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8474924451354475\n"
     ]
    }
   ],
   "source": [
    "def distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate distance between two points\n",
    "    \"\"\"\n",
    "    return mpu.haversine_distance(point1, point2)\n",
    "\n",
    "print(distance((30.170165, -97.756954), (30.277500,-97.713975))/km_per_mi)\n",
    "\n",
    "def closest(data, this_point):\n",
    "    \"\"\"\n",
    "    Applies the distance function to each element in the data, \n",
    "    then returns the observation with the lowest distance.\n",
    "    \"\"\"\n",
    "    return min(data, key=lambda x: distance(this_point,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_with_neigh = np.array(not_missing_neigh[['avg_lat', 'avg_lon']])\n",
    "coords_no_neigh = np.array(missing_neigh[['avg_lat', 'avg_lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighborhood identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify neighborhoods for properties with no neighborhood assigned\n",
    "# NOTE: IF THIS HAS BEEN RUN ONCE, CAN COMMENT OUT AND JUST LOAD IN 'approximated_neighs.csv'\n",
    "\n",
    "neigh_timer = time.time()\n",
    "\n",
    "approx_neighs = []\n",
    "\n",
    "for i in coords_no_neigh:\n",
    "     approx_neighs.append(not_missing_neigh[(not_missing_neigh['avg_lat'] == closest(tuple(coords_with_neigh), tuple(i))[0]) & (not_missing_neigh['avg_lon'] == closest(tuple(coords_with_neigh), tuple(i))[1])]['neighbourhood'].values[0])\n",
    "\n",
    "missing_neigh['neighbourhood'] = approx_neighs\n",
    "\n",
    "# # Save the approximate neighborhoods so this code doesn't need to be run again.\n",
    "missing_neigh.to_csv('approximated_neighs.csv', index=False)\n",
    "\n",
    "# time_to_match = time.time() - neigh_timer\n",
    "\n",
    "# print(\"Mins to match neighborhoods:\")\n",
    "# print(time_to_match/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If approximated_neighs.csv exists, can load in neighborhoods here.\n",
    "missing_neigh['neighbourhood'] = pd.read_csv('approximated_neighs.csv')['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37769/445639951.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  listings_df.loc[:, 'neighbourhood'][missing_neigh['index'].values] = missing_neigh['neighbourhood'].values\n"
     ]
    }
   ],
   "source": [
    "listings_df.loc[:, 'neighbourhood'][missing_neigh['index'].values] = missing_neigh['neighbourhood'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all of the 0's with NaN's\n",
    "listings_df.loc[:, 'neighbourhood'] = listings_df['neighbourhood'].replace({0: np.nan})\n",
    "\n",
    "# Copy the neighborhood over the whole sample\n",
    "listings_df.loc[:,'neighbourhood'] = listings_df.groupby(['id'])['neighbourhood'].fillna(method='ffill', axis=0)\n",
    "listings_df.loc[:, 'neighbourhood'] = listings_df.groupby(['id'])['neighbourhood'].fillna(method='bfill', axis=0)\n",
    "\n",
    "# Create neighborhood dummies\n",
    "create_dummies('neighbourhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>avg_lat</th>\n",
       "      <th>avg_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [neighbourhood, avg_lat, avg_lon]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df[listings_df['id'] == 7807841][['neighbourhood', 'avg_lat', 'avg_lon']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calendar Formatting\n",
    "\n",
    "Here I calculate a numeric value for the days since an Airbnb listing's calendar has been updated. This offers a measure for how active the Airbnb property is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_update = listings_df['calendar_updated'].str.split(\" \", n=2, expand=True)\n",
    "cal_update.columns = ['count', 'units', 'numeric']\n",
    "\n",
    "cal_update = cal_update[['count', 'units']] # Drop the third column\n",
    "cal_update.loc[:, \"count\"] = cal_update['count'].replace({\"today\": 0, \"a\":1, \"yesterday\":0, \"never\":9999}).astype(float)\n",
    "cal_update.loc[:, \"units\"] = cal_update['units'].replace({\"days\": 1, \"None\":1, \"weeks\":7, \"months\":30, \"week\":7}).astype(float)\n",
    "cal_update.loc[:, 'days'] = cal_update['count']*cal_update['units']\n",
    "\n",
    "cal_update.loc[cal_update['count']==0.0, \"days\"] = 0.0\n",
    "cal_update.loc[cal_update['count']==9999, \"days\"] = 9999\n",
    "\n",
    "# Add the calendar update values to the dataframe\n",
    "listings_df.loc[:, 'days_since_calup'] = cal_update['days']\n",
    "del cal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing neighborhoods flag\n",
    "listings_df = listings_df.drop(columns=['missing_neigh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(csv_save_path)\n",
    "listings_df.to_csv('1stStageClean_Portland.csv.gz', compression='gzip', index=False, date_format='%Y-%m-%d %H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
