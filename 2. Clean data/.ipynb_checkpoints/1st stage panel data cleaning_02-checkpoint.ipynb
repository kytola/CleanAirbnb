{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Stage Panel Data Cleaning\n",
    "\n",
    "This notebook performs the first round of less controversial data cleaning tasks on the final long form data produced from the aggregate data notebook. These tasks include creating leads and lags, general formatting, filling N/A values, and identifying missing neighborhoods. It then saves the cleaned data into a csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Links and Documentation\n",
    "* **Reverse-geocoder:** https://github.com/thampiman/reverse-geocoder, https://pypi.org/project/reverse_geocoder/\n",
    "* **Filling in missing values:** https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html\n",
    "* **Label encoding:** https://pbpython.com/categorical-encoding.html\n",
    "* **mpu for distance:** https://stackoverflow.com/questions/41336756/find-the-closest-latitude-and-longitude\n",
    "* **Filled forward with Numpy:** https://stackoverflow.com/questions/41190852/most-efficient-way-to-forward-fill-nan-values-in-numpy-array\n",
    "* **Passing an operator to a Python function:** https://stackoverflow.com/questions/18591778/how-to-pass-an-operator-to-a-python-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import operator # This allows one to pass operators into a Python function\n",
    "import datetime\n",
    "import mpu # For distance calculation\n",
    "from scipy import stats\n",
    "import quantecon as qe\n",
    "import reverse_geocoder as rg #for neighborhood identification\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_per_mi = 1.60934 #for conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal directory setup\n",
    "cwd1 = os.getcwd() \n",
    "\n",
    "# Go up one directory level\n",
    "os.chdir('..')\n",
    "cwd2 = os.getcwd()\n",
    "\n",
    "# Make sure repository has a 2. Clean data and Saved data folders!\n",
    "csv_raw_path = cwd2 + '/2. Clean data'\n",
    "csv_save_path = cwd2 + '/Saved data'\n",
    "csv_GOOGLE_save = cwd2 + '/Saved data'\n",
    "# Revert to preliminary directory\n",
    "os.chdir(cwd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read concatenated data\n",
    "os.chdir(csv_raw_path)\n",
    "\n",
    "listings_df = pd.read_csv('Data_longALL_v1.csv.gz', low_memory=False)\n",
    "\n",
    "# Switch to other folder for saving data\n",
    "os.chdir(csv_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destringing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destring_price(var):\n",
    "    \"\"\"\n",
    "    Destrings a passed variable.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = listings_df[var].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "for var in ['price', 'weekly_price', 'monthly_price', 'security_deposit', 'cleaning_fee', 'extra_people']:\n",
    "    destring_price(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-65710870a3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdate_vars\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'last_scraped'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'host_since'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'first_review'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'last_review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mformat_dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Set the 'scrape_batch' as a modal date for a file being scraped in a CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-65710870a3ea>\u001b[0m in \u001b[0;36mformat_dates\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mconverts\u001b[0m \u001b[0mdate\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0minto\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlistings_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistings_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdate_vars\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'last_scraped'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'host_since'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'first_review'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'last_review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def format_dates(var):\n",
    "    \"\"\"\n",
    "    This function converts date variables into datetime format.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = pd.to_datetime(listings_df[var])\n",
    "    \n",
    "for date_vars in ['last_scraped', 'host_since', 'first_review', 'last_review']:\n",
    "    format_dates(date_vars)\n",
    "    \n",
    "# Set the 'scrape_batch' as a modal date for a file being scraped in a CSV\n",
    "\n",
    "for m in listings_df['month'].unique():\n",
    "    listings_df.loc[listings_df['month'] == m, 'scrape_batch'] = listings_df[listings_df['month'] == m]['last_scraped'].mode().values[0]\n",
    "    listings_df.loc[:, 'scrape_batch'] = pd.to_datetime(listings_df['scrape_batch'])\n",
    "    \n",
    "# Create a YR, MO value for the scrape batch, this is largely used for graphing where one needs to aggregate by year-month\n",
    "listings_df.loc[:,\"batch_YRMO\"] = pd.to_datetime(listings_df['scrape_batch']).dt.to_period('M')    \n",
    "\n",
    "\n",
    "def dates_diff(var_name, var1, var2):\n",
    "    \"\"\"\n",
    "    Computes the difference between two date variables and assigns\n",
    "    the difference to a new variable of given name.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var_name] = listings_df[var1] - listings_df[var2]\n",
    "\n",
    "dates_diff('days_since_rev', 'last_scraped', 'last_review')\n",
    "dates_diff('days_since_first_rev', 'last_scraped', 'first_review')\n",
    "dates_diff('host_length', 'last_scraped', 'host_since')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leads and lag creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagsleads(var, lag_range, df, title):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function creates lag variables within a given range \n",
    "    for a given variable within a given dataframe. The title of these lag \n",
    "    variables is specified by title.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.sort_values(by = ['id', 'month'])\n",
    "    \n",
    "    for i in range(-lag_range, lag_range + 1):\n",
    "        \n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        if i < 0:\n",
    "            df.loc[:, title + \"lead\" + str(abs(i)) ] = df.groupby('id')[var].shift(i)\n",
    "                \n",
    "        if i > 0: \n",
    "            df.loc[:, title + \"lag\" + str(abs(i)) ] = df.groupby('id')[var].shift(i)\n",
    "            \n",
    "    return df\n",
    "\n",
    "listings_df = create_lagsleads('List_month', 12, listings_df, \"List\") # This would be much faster in numpy...\n",
    "listings_df = create_lagsleads('availability_60', 12, listings_df, \"avail60\")\n",
    "listings_df = create_lagsleads('availability_90', 12, listings_df, \"avail90\")\n",
    "listings_df = create_lagsleads('availability_365', 12, listings_df, \"avail365\")\n",
    "# listings_df = create_lagsleads('number_of_reviews', 12, listings_df, \"NOR\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional formatting\n",
    "\n",
    "listings_df = listings_df.reset_index(drop=True)\n",
    "\n",
    "listings_df.loc[:, 'max_lag'] = listings_df.groupby(['id'])['number_of_reviews'].rolling(4).max().reset_index(level=0, drop=True)\n",
    "listings_df['max_lag'].fillna(listings_df['number_of_reviews'], inplace=True)\n",
    "listings_df.loc[:, 'fixed_lag'] = listings_df.groupby('id')['max_lag'].shift(1)\n",
    "listings_df.loc[:, \"NOR_diff\"] = listings_df['max_lag'] - listings_df['fixed_lag']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks what the difference between the number of unique ids and the number of ids paired with some\n",
    "# property characteristic. The key thing here is to see whether or not a listing trait changes\n",
    "\n",
    "def checking_missing_data(var):\n",
    "    \"\"\"\n",
    "    This function checks what the difference between the number of unique ids and the \n",
    "    number of ids paired with some property characteristic. \n",
    "    The key use case is to see whether or not a listing trait changes.\n",
    "    \"\"\"\n",
    "    \n",
    "    ids = listings_df[['id']].drop_duplicates().dropna()\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    paired_ids = listings_df[['id', var]].dropna().drop_duplicates()\n",
    "    paired_ids = np.array(paired_ids)\n",
    "    \n",
    "    if len(ids) == len(paired_ids):\n",
    "        print('No change in variable')\n",
    "    else:\n",
    "        print(\"Variable changes\")\n",
    "              \n",
    "#     return set(ids[:,0]) - set(paired_ids[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def identify_variable_changes(var, cutoff, relate, df):\n",
    "    \"\"\"\n",
    "    This function produces ids where the variable of interest changes.\n",
    "    \"\"\"\n",
    "    ops = {'>': operator.gt,\n",
    "       '<': operator.lt,\n",
    "       '>=': operator.ge,\n",
    "       '<=': operator.le,\n",
    "       '==': operator.eq}\n",
    "    \n",
    "    # Take ids and variable of interest and drop any na's\n",
    "    repetition_arr = np.array(df[['id', var]].dropna().drop_duplicates()) # Need drop_duplicates to identify actual price changes\n",
    "    counts = np.unique(repetition_arr[:,0], return_counts = True)\n",
    "    return counts[0][ops[relate](counts[1], cutoff)], counts[1][ops[relate](counts[1], cutoff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_vars, change_counts = identify_variable_changes('longitude', 7, \">=\", listings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 472901., 1392204., 7309811., 8053887., 8446662., 9284412.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zipcode, dtype: object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df[listings_df['id']==19490974]['zipcode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling in N/A's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the code fills missing data in forwards and backwards for values that would be expected to be invariant over time such as fixed property features and host characteristics, such as when the host first started using Airbnb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the modal zip codes as a property's zip code\n",
    "modal_zips = listings_df.groupby('id')['zipcode'].agg(lambda x: stats.mode(x)[0][0])\n",
    "listings_df.loc[:, 'zipcode'] = modal_zips[listings_df['id']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption: Properties do not change features when they are no observed\n",
    "Forward fill, then back fill. This means older properties have priority. This is an assumption! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC: Elapsed: 0:02:16.61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "136.61671566963196"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This loop takes 4 minutes.\n",
    "\n",
    "qe.util.tic()\n",
    "\n",
    "#Fill loop\n",
    "for var in ['host_id', 'host_name', 'host_since', 'host_location', 'property_type', 'room_type', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'first_review', 'instant_bookable']:\n",
    "    listings_df.loc[:, var] = listings_df.groupby(['id'])[var].fillna(method='ffill', axis=0)\n",
    "    listings_df.loc[:, var] = listings_df.groupby(['id'])[var].fillna(method='bfill', axis=0)\n",
    "    \n",
    "qe.util.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(var):\n",
    "    \"\"\"\n",
    "    Creates a dummy variable for a given variable\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = listings_df[var].astype('category')\n",
    "    listings_df.loc[:, var + \"_dum\"] = listings_df[var].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['host_is_superhost', 'room_type', 'instant_bookable', 'zipcode']\n",
    "\n",
    "#creates dummy variables for all categories\n",
    "for cat in categorical_vars:\n",
    "    create_dummies(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood categorization\n",
    "This section attempts to classify each property as belonging to a specific neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding appropriate neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total listings:\n",
      "1790982\n",
      "-------------------------\n",
      "Active listings with neighborhood reported:\n",
      "416799\n",
      "-------------------------\n",
      "Active listings with no neighborhood reported:\n",
      "21792\n"
     ]
    }
   ],
   "source": [
    "# How many total listings there are \n",
    "print(\"Total listings:\")\n",
    "\n",
    "print(len(listings_df['neighbourhood'].astype('category')))\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Active listings with neighborhood reported:\")\n",
    "print(len(listings_df[(listings_df['List_month']==1) & (~listings_df['neighbourhood'].isna())]))\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Active listings with no neighborhood reported:\")\n",
    "print(len(listings_df[(listings_df['List_month']==1) & (listings_df['neighbourhood'].isna())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code replaces each listing's neighborhood with its modal neighborhood\n",
    "modal_neighs = listings_df.groupby('id')['neighbourhood'].agg(lambda x: stats.mode(x)[0][0])\n",
    "listings_df.loc[:, 'neighbourhood'] = modal_neighs[listings_df['id']].values\n",
    "\n",
    "# Creates a dummy for whether neighborhood was initially reported\n",
    "listings_df.loc[:, 'missing_neigh'] = (listings_df['neighbourhood'] == 0)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average the reported longitude and latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_avg_lat, id_avg_lon = listings_df.groupby('id')['latitude'].mean(), listings_df.groupby('id')['longitude'].mean()\n",
    "\n",
    "listings_df.loc[:,'avg_lat'] = np.array(id_avg_lat[(listings_df['id'].values)])\n",
    "listings_df.loc[:, 'avg_lon'] = np.array(id_avg_lon[(listings_df['id'].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up a dataframe of all of the listings missing a neighborhood\n",
    "missing_neigh = listings_df[(listings_df['List_month'] == 1) & (listings_df['neighbourhood'] == 0) & (~listings_df['latitude'].isna()) & (~listings_df['longitude'].isna())][['id', 'avg_lat', 'avg_lon']]\n",
    "missing_neigh = missing_neigh.drop_duplicates()\n",
    "missing_neigh = missing_neigh.sort_index()\n",
    "missing_neigh = missing_neigh.reset_index(drop = False)\n",
    "\n",
    "# Dataframe of all the listings, that are not missing a neighborhood\n",
    "not_missing_neigh = listings_df[(listings_df['List_month'] == 1) & (listings_df['neighbourhood'] != 0) & (~listings_df['latitude'].isna()) & (~listings_df['longitude'].isna())][['id', 'neighbourhood','avg_lat', 'avg_lon']]\n",
    "not_missing_neigh = not_missing_neigh.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>avg_lat</th>\n",
       "      <th>avg_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37526</td>\n",
       "      <td>340586</td>\n",
       "      <td>37.771045</td>\n",
       "      <td>-122.463453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46001</td>\n",
       "      <td>464078</td>\n",
       "      <td>37.787714</td>\n",
       "      <td>-122.445258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64555</td>\n",
       "      <td>666434</td>\n",
       "      <td>37.790655</td>\n",
       "      <td>-122.406108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67109</td>\n",
       "      <td>696724</td>\n",
       "      <td>37.809686</td>\n",
       "      <td>-122.366324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67164</td>\n",
       "      <td>696756</td>\n",
       "      <td>37.789434</td>\n",
       "      <td>-122.406579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>1458965</td>\n",
       "      <td>24851531</td>\n",
       "      <td>37.801871</td>\n",
       "      <td>-122.407755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1729955</td>\n",
       "      <td>38073895</td>\n",
       "      <td>37.828790</td>\n",
       "      <td>-122.376610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>1790684</td>\n",
       "      <td>40539735</td>\n",
       "      <td>37.801010</td>\n",
       "      <td>-122.415900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>1790858</td>\n",
       "      <td>40547706</td>\n",
       "      <td>37.817040</td>\n",
       "      <td>-122.369990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>1790916</td>\n",
       "      <td>40560328</td>\n",
       "      <td>37.791790</td>\n",
       "      <td>-122.430210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1934 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        id    avg_lat     avg_lon\n",
       "0       37526    340586  37.771045 -122.463453\n",
       "1       46001    464078  37.787714 -122.445258\n",
       "2       64555    666434  37.790655 -122.406108\n",
       "3       67109    696724  37.809686 -122.366324\n",
       "4       67164    696756  37.789434 -122.406579\n",
       "...       ...       ...        ...         ...\n",
       "1929  1458965  24851531  37.801871 -122.407755\n",
       "1930  1729955  38073895  37.828790 -122.376610\n",
       "1931  1790684  40539735  37.801010 -122.415900\n",
       "1932  1790858  40547706  37.817040 -122.369990\n",
       "1933  1790916  40560328  37.791790 -122.430210\n",
       "\n",
       "[1934 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8474924451354475\n"
     ]
    }
   ],
   "source": [
    "def distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate distance between two points\n",
    "    \"\"\"\n",
    "    return mpu.haversine_distance(point1, point2)\n",
    "\n",
    "print(distance((30.170165, -97.756954), (30.277500,-97.713975))/km_per_mi)\n",
    "\n",
    "def closest(data, this_point):\n",
    "    \"\"\"\n",
    "    Applies the distance function to each element in the data, \n",
    "    then returns the observation with the lowest distance.\n",
    "    \"\"\"\n",
    "    return min(data, key=lambda x: distance(this_point,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_with_neigh = np.array(not_missing_neigh[['avg_lat', 'avg_lon']])\n",
    "coords_no_neigh = np.array(missing_neigh[['avg_lat', 'avg_lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighborhood identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC: Elapsed: 0:06:11.31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "371.31531143188477"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code takes around 8 minutes.\n",
    "\n",
    "qe.util.tic()\n",
    "\n",
    "approx_neighs = []\n",
    "\n",
    "for i in coords_no_neigh:\n",
    "    approx_neighs.append(not_missing_neigh[(not_missing_neigh['avg_lat'] == closest(tuple(coords_with_neigh), tuple(i))[0]) & (not_missing_neigh['avg_lon'] == closest(tuple(coords_with_neigh), tuple(i))[1])]['neighbourhood'].values[0])\n",
    "\n",
    "missing_neigh['neighbourhood'] = approx_neighs\n",
    "missing_neigh.to_csv('approximated_neighs.csv', index=False)\n",
    "\n",
    "qe.util.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_neigh['neighbourhood'] = pd.read_csv('approximated_neighs.csv')['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: neighbourhood, dtype: object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df[listings_df['id'] == 8971967]['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-d2d97b433a03>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  listings_df.loc[:, 'neighbourhood'][missing_neigh['index'].values] = missing_neigh['neighbourhood'].values\n"
     ]
    }
   ],
   "source": [
    "listings_df.loc[:, 'neighbourhood'][missing_neigh['index'].values] = missing_neigh['neighbourhood'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: neighbourhood, dtype: object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df[listings_df['id'] == 8971967]['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all of the 0's with NaN's\n",
    "listings_df.loc[:, 'neighbourhood'] = listings_df['neighbourhood'].replace({0: np.nan})\n",
    "\n",
    "# Copy the neighborhood over the whole sample\n",
    "listings_df.loc[:,'neighbourhood'] = listings_df.groupby(['id'])['neighbourhood'].fillna(method='ffill', axis=0)\n",
    "listings_df.loc[:, 'neighbourhood'] = listings_df.groupby(['id'])['neighbourhood'].fillna(method='bfill', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>avg_lat</th>\n",
       "      <th>avg_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [neighbourhood, avg_lat, avg_lon]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df[listings_df['id'] == 8971967][['neighbourhood', 'avg_lat', 'avg_lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dummies('neighbourhood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calendar Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cal_update = listings_df['calendar_updated'].str.split(\" \", n=2, expand=True)\n",
    "cal_update.columns = ['count', 'units', 'numeric']\n",
    "\n",
    "cal_update = cal_update[['count', 'units']] # Drop the third column\n",
    "cal_update.loc[:, \"count\"] = cal_update['count'].replace({\"today\": 0, \"a\":1, \"yesterday\":0, \"never\":9999}).astype(float)\n",
    "cal_update.loc[:, \"units\"] = cal_update['units'].replace({\"days\": 1, \"None\":1, \"weeks\":7, \"months\":30, \"week\":7}).astype(float)\n",
    "cal_update.loc[:, 'days'] = cal_update['count']*cal_update['units']\n",
    "\n",
    "cal_update.loc[cal_update['count']==0.0, \"days\"] = 0.0\n",
    "cal_update.loc[cal_update['count']==9999, \"days\"] = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df.loc[:, 'days_since_calup'] = cal_update['days']\n",
    "del cal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1790982"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listings_df[listings_df['NOR_diff'] < 0]) + len(listings_df[listings_df['NOR_diff'] >= 0]) + len(listings_df[listings_df['NOR_diff'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>month</th>\n",
       "      <th>List_month</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>...</th>\n",
       "      <th>NOR_diff</th>\n",
       "      <th>host_is_superhost_dum</th>\n",
       "      <th>room_type_dum</th>\n",
       "      <th>instant_bookable_dum</th>\n",
       "      <th>zipcode_dum</th>\n",
       "      <th>missing_neigh</th>\n",
       "      <th>avg_lat</th>\n",
       "      <th>avg_lon</th>\n",
       "      <th>neighbourhood_dum</th>\n",
       "      <th>days_since_calup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6284</td>\n",
       "      <td>958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-02</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>Holly</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>San Francisco, California, United States</td>\n",
       "      <td>within a day</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>37.76931</td>\n",
       "      <td>-122.433853</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37163</td>\n",
       "      <td>958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>Holly</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>San Francisco, California, United States</td>\n",
       "      <td>within a day</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>37.76931</td>\n",
       "      <td>-122.433853</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68042</td>\n",
       "      <td>958</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>Holly</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>San Francisco, California, United States</td>\n",
       "      <td>within a day</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>37.76931</td>\n",
       "      <td>-122.433853</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98921</td>\n",
       "      <td>958</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>Holly</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>San Francisco, California, United States</td>\n",
       "      <td>within a day</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>37.76931</td>\n",
       "      <td>-122.433853</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129800</td>\n",
       "      <td>958</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>Holly</td>\n",
       "      <td>2008-07-31</td>\n",
       "      <td>San Francisco, California, United States</td>\n",
       "      <td>within a day</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>37.76931</td>\n",
       "      <td>-122.433853</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   id  month  List_month last_scraped  host_id host_name  \\\n",
       "0        6284  958      0           1   2015-09-02   1169.0     Holly   \n",
       "1       37163  958      1           1   2015-11-01   1169.0     Holly   \n",
       "2       68042  958      2           1   2015-12-02   1169.0     Holly   \n",
       "3       98921  958      3           1   2016-02-02   1169.0     Holly   \n",
       "4      129800  958      4           1   2016-04-03   1169.0     Holly   \n",
       "\n",
       "  host_since                             host_location host_response_time  \\\n",
       "0 2008-07-31  San Francisco, California, United States       within a day   \n",
       "1 2008-07-31  San Francisco, California, United States       within a day   \n",
       "2 2008-07-31  San Francisco, California, United States       within a day   \n",
       "3 2008-07-31  San Francisco, California, United States       within a day   \n",
       "4 2008-07-31  San Francisco, California, United States       within a day   \n",
       "\n",
       "   ... NOR_diff host_is_superhost_dum  room_type_dum  instant_bookable_dum  \\\n",
       "0  ...      NaN                     0              0                     0   \n",
       "1  ...      2.0                     0              0                     0   \n",
       "2  ...      1.0                     0              0                     0   \n",
       "3  ...      3.0                     0              0                     0   \n",
       "4  ...      5.0                     0              0                     0   \n",
       "\n",
       "  zipcode_dum missing_neigh   avg_lat     avg_lon  neighbourhood_dum  \\\n",
       "0          30             0  37.76931 -122.433853                 15   \n",
       "1          30             0  37.76931 -122.433853                 15   \n",
       "2          30             0  37.76931 -122.433853                 15   \n",
       "3          30             0  37.76931 -122.433853                 15   \n",
       "4          30             0  37.76931 -122.433853                 15   \n",
       "\n",
       "   days_since_calup  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves file to the file location, 'csv_GOOGLE_save', specified in universal directory\n",
    "os.chdir(csv_GOOGLE_save)\n",
    "listings_df.to_csv('1stStageClean_AUS.csv', index=False, date_format='%Y-%m-%d %H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
