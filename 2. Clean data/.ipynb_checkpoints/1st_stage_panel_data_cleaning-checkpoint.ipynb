{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Stage Panel Data Cleaning\n",
    "\n",
    "This notebook performs the first round of data cleaning tasks on the final long form data produced from the Aggregate Listings Data notebook. These tasks include:\n",
    "\n",
    "* 1. **Preliminary cleaning:** Includes de-stringing prices, formatting dates and computing variable lags and leads\n",
    "* 2. **Exploring missing values:** Creates functions for understanding NaN values and fills in time-invariant characteristics of a listing\n",
    "* 3. **Neighborhood categorization:** Assign neighborhoods to listings based on their GPS coordinates \n",
    "* 4. **'Calendar Update' formatting:** Creating numerical measure for how often an Airbnb listing is updated by the property host\n",
    "* 5. **Additional variable creation:** Additional variables are created for further anaylsis\n",
    "* 6. **Creating drop criteria for observations:** Primary focus of drop criteria is to drop dormant listings, price outliers and full-time hotels\n",
    "\n",
    "Once these tasks are complete, the Notebook saves the cleaned data into a compressed csv.gz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import operator # This allows one to pass operators into a Python function\n",
    "import mpu # For distance calculation\n",
    "from scipy import stats # Used to find modal value of geographic values\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select city to work with\n",
    "\n",
    "city_folder = '/united-states_portland'\n",
    "city_abbrev = 'POR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal directory setup\n",
    "cwd1 = os.getcwd() \n",
    "\n",
    "# Go up one directory level\n",
    "os.chdir('..')\n",
    "cwd2 = os.getcwd()\n",
    "\n",
    "csv_raw_path = cwd2 + '/1. Download and compile data/'\n",
    "csv_save_path = cwd2 + '/Saved data/'\n",
    "\n",
    "# Revert to preliminary directory\n",
    "os.chdir(cwd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  month  List_month last_scraped     host_id       host_name\n",
      "0  4986792      0           1   2015-09-02   9165660.0         Cynthia\n",
      "1  3883718      0           1   2015-09-02  13686663.0         Mallory\n",
      "2  7092722      0           1   2015-09-02  13322905.0           Sarah\n",
      "3  4475369      0           1   2015-09-02   4006487.0        Kathleen\n",
      "4  5904142      0           1   2015-09-02  19052765.0  Melanie & Dirk\n",
      "5  2455288      0           1   2015-09-02  11021785.0             Amy\n"
     ]
    }
   ],
   "source": [
    "# Read concatenated data\n",
    "os.chdir(csv_raw_path)\n",
    "\n",
    "listings_df = pd.read_csv(city_abbrev + '_Data_longALL.csv.gz', low_memory=False)\n",
    "\n",
    "# Switch to other folder for saving data\n",
    "os.chdir(csv_save_path)\n",
    "\n",
    "# Show a snapshot of the dataframe\n",
    "print(listings_df.iloc[:6,:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# 1. Preliminary Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destringing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destring_price(var):\n",
    "    \"\"\"\n",
    "    Destrings a passed variable.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = listings_df[var].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# This loop destrings price variables\n",
    "for var in ['price', 'weekly_price', \n",
    "            'monthly_price', 'security_deposit',\n",
    "            'cleaning_fee', 'extra_people']:\n",
    "    \n",
    "    destring_price(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dates(var):\n",
    "    \"\"\"\n",
    "    This function converts date variables into datetime format.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = pd.to_datetime(listings_df[var])\n",
    "    \n",
    "# ===============================================================    \n",
    "\n",
    "def dates_diff(var_name, var1, var2):\n",
    "    \"\"\"\n",
    "    Computes the difference between two date variables and assigns\n",
    "    the difference to a new variable of given name.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var_name] = listings_df[var1] - listings_df[var2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a loop of date formatting\n",
    "for date_vars in ['last_scraped', 'host_since', 'first_review', 'last_review']:\n",
    "    format_dates(date_vars)\n",
    "    \n",
    "# Set the 'scrape_batch' as a modal date for a file being scraped in a CSV\n",
    "\n",
    "for m in listings_df['month'].unique():\n",
    "    listings_df.loc[listings_df['month'] == m, 'scrape_batch'] = listings_df[listings_df['month'] == m]['last_scraped'].mode().values[0]\n",
    "    listings_df.loc[:, 'scrape_batch'] = pd.to_datetime(listings_df['scrape_batch'])\n",
    "    \n",
    "# Create a Year-Month value for the scrape batch, this is largely used for graphing where one needs to aggregate by year-month\n",
    "listings_df.loc[:,\"batch_YRMO\"] = pd.to_datetime(listings_df['scrape_batch']).dt.to_period('M')    \n",
    "\n",
    "# Calculate different date differences\n",
    "dates_diff('days_since_rev', 'last_scraped', 'last_review')\n",
    "dates_diff('days_since_first_rev', 'last_scraped', 'first_review')\n",
    "dates_diff('host_length', 'last_scraped', 'host_since')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timedelta_formatter(var):\n",
    "    \"\"\"\n",
    "    This function formats the time delta for a passed variable.\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = pd.to_timedelta(listings_df[var]).dt.days\n",
    "    \n",
    "for deltas in ['days_since_rev', 'days_since_first_rev', 'host_length']:\n",
    "    timedelta_formatter(deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leads and lag creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagsleads(var, lag_range, df, title):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function creates lag variables within a given range \n",
    "    for a given variable within a given dataframe. The title of these lag \n",
    "    variables is specified by title.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.sort_values(by = ['id', 'month']).copy()\n",
    "    \n",
    "    for i in range(-lag_range, lag_range + 1):\n",
    "        \n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        if i < 0:\n",
    "            df.loc[:, title + \"lead\" + str(abs(i)) ] = df.groupby('id')[var].shift(i).copy()\n",
    "                \n",
    "        if i > 0: \n",
    "            df.loc[:, title + \"lag\" + str(abs(i)) ] = df.groupby('id')[var].shift(i).copy()\n",
    "            \n",
    "    return df\n",
    "\n",
    "listings_df = create_lagsleads('List_month', 12, listings_df, \"List\")\n",
    "listings_df = create_lagsleads('availability_60', 12, listings_df, \"avail60\")\n",
    "listings_df = create_lagsleads('availability_90', 12, listings_df, \"avail90\")\n",
    "listings_df = create_lagsleads('availability_365', 12, listings_df, \"avail365\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df = listings_df.reset_index(drop=True)\n",
    "\n",
    "# Count the number of unique months in the concatenated dataset\n",
    "Nunique_months = len(listings_df['month'].unique())\n",
    "\n",
    "# Create a clean measure for the number of reviews that prevents reviews from falling over time. This is done \n",
    "# so that changes in reviews can be used to get a sense of bookings.\n",
    "listings_df.loc[:, 'corrected_NOR'] = listings_df.groupby(['id'])['number_of_reviews'].rolling(Nunique_months, min_periods=1).max().reset_index(level=0, drop=True)\n",
    "listings_df = create_lagsleads('corrected_NOR', 12, listings_df, \"NOR\") \n",
    "listings_df.loc[:, \"NOR_diff\"] = listings_df['corrected_NOR'] - listings_df['NORlag1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on the 'NOR_diff' variable\n",
    "* The measure for the differences in the number of reviews is imperfect but seems generally reasonable, researchers need to be careful with how it is used. \n",
    "\n",
    "* As long as properties appear in consecutive scrapes it seems to work well. If a property does not appear for many scrapes and reviews will sometimes jump significantly when it reappears. \n",
    "\n",
    "* When describing the 'NOR_diff' variable, we can observe the maximum number of reviews in a given month is 149! Which is not a reasonable number of reviews for a property to recieve in in 30/31 days. \n",
    "\n",
    "* It may be desirable to make an assumption that reviews are evenly across the months in which the property fails to appear in the scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    253504.000000\n",
      "mean          1.537246\n",
      "std           3.161950\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           2.000000\n",
      "max         149.000000\n",
      "Name: NOR_diff, dtype: float64\n",
      "----\n",
      "99th percentile:\n",
      "14.0\n"
     ]
    }
   ],
   "source": [
    "# Describe the 'NOR_diff variable\n",
    "print(listings_df['NOR_diff'].describe())\n",
    "\n",
    "# Report 99th percentile of difference in number of reviews\n",
    "print(\"----\")\n",
    "print('99th percentile:')\n",
    "print(np.quantile(listings_df[~(listings_df['NOR_diff'].isna())]['NOR_diff'], 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month  number_of_reviews  corrected_NOR  NOR_diff\n",
      "159451     18               51.0           51.0       2.0\n",
      "159452     19                NaN           51.0       0.0\n",
      "159453     20                NaN           51.0       0.0\n",
      "159454     21                NaN           51.0       0.0\n",
      "159455     22                NaN           51.0       0.0\n",
      "159456     23               55.0           55.0       4.0\n",
      "159457     24               51.0           55.0       0.0\n",
      "159458     25               51.0           55.0       0.0\n",
      "159459     26               51.0           55.0       0.0\n",
      "159460     27               59.0           59.0       4.0\n",
      "159461     28               61.0           61.0       2.0\n"
     ]
    }
   ],
   "source": [
    "# Example of what the corrected_NOR variable does. Can see that I don't allow the stock of reviews to decline.\n",
    "\n",
    "print(listings_df[listings_df['id'] == 10886050][['month', \n",
    "                                                  'number_of_reviews',\n",
    "                                                  'corrected_NOR', 'NOR_diff']].iloc[-19:-8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploring missing data and filling in NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_missing_data(var):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function checks what the difference between the number of unique ids and the \n",
    "    number of ids is paired with some property characteristic. \n",
    "    The key use case is to see whether or not a listing trait changes.\n",
    "    \"\"\"\n",
    "    \n",
    "    ids = listings_df[['id']].drop_duplicates().dropna()\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    paired_ids = listings_df[['id', var]].dropna().drop_duplicates()\n",
    "    paired_ids = np.array(paired_ids)\n",
    "    \n",
    "    if len(ids) == len(paired_ids):\n",
    "        print('No change in variable')\n",
    "    else:\n",
    "        print(\"Variable changes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_variable_changes(var, cutoff, relate, df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function lists ids where the variable of interest changes (\"var\").\n",
    "    This can be used for data cleaning purposes.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops = {'>': operator.gt,\n",
    "       '<': operator.lt,\n",
    "       '>=': operator.ge,\n",
    "       '<=': operator.le,\n",
    "       '==': operator.eq}\n",
    "    \n",
    "    # Take ids and variable of interest and drop any na's\n",
    "    repetition_arr = np.array(df[['id', var]].dropna().drop_duplicates()) # Need drop_duplicates to identify actual price changes\n",
    "    counts = np.unique(repetition_arr[:,0], return_counts = True)\n",
    "    \n",
    "    return counts[0][ops[relate](counts[1], cutoff)], counts[1][ops[relate](counts[1], cutoff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique ids that changed their official 'property type:'\n",
      "1637\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the identify variable changes function\n",
    "\n",
    "# Store the ids for which the property type changes at least twice\n",
    "change_ids, change_counts = identify_variable_changes('property_type', 2, '>=', listings_df)\n",
    "\n",
    "# Unique ids that report changed property types\n",
    "print(\"Number of unique ids that changed their official 'property type:'\")\n",
    "print(len(change_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in N/A's\n",
    "This section of the code fills missing data in forwards and backwards for values that would be expected to be invariant over time, such as fixed property features and host characteristics, during times for example when the host first started using Airbnb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the modal zip codes as a property's zip code\n",
    "modal_zips = listings_df.groupby('id')['zipcode'].agg(lambda x: stats.mode(x)[0][0])\n",
    "listings_df.loc[:, 'zipcode'] = modal_zips[listings_df['id']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption: Properties do not change features when they are not observed\n",
    "Forward fill, then back fill. This means older features have priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minutes to run filling loop:\n",
      "1.007814633846283\n"
     ]
    }
   ],
   "source": [
    "# Run a loop that fills property characteristics forwards and backwards\n",
    "\n",
    "my_timer = time.time() # Time it\n",
    "\n",
    "for var in ['host_id', 'host_name', 'host_since', 'host_location', 'property_type', 'room_type', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'first_review', 'instant_bookable']:\n",
    "    listings_df.loc[:, var] = listings_df.groupby(['id'])[var].fillna(method='ffill', axis=0)\n",
    "    listings_df.loc[:, var] = listings_df.groupby(['id'])[var].fillna(method='bfill', axis=0)\n",
    "    \n",
    "time_to_run_filler =  time.time() - my_timer\n",
    "\n",
    "print(\"Minutes to run filling loop:\")\n",
    "print(time_to_run_filler/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(var):\n",
    "    \"\"\"\n",
    "    Creates a dummy variable for a given variable\n",
    "    \"\"\"\n",
    "    listings_df.loc[:, var] = listings_df[var].astype('category')\n",
    "    listings_df.loc[:, var + \"_dum\"] = listings_df[var].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dummy variables for specified categories\n",
    "\n",
    "categorical_vars = ['host_is_superhost', 'room_type', 'instant_bookable', 'zipcode']\n",
    "\n",
    "for cat in categorical_vars:\n",
    "    create_dummies(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neighborhood categorization\n",
    "This section assigns each property to a specific neighborhood. There are two primary cases to be worried about:\n",
    "\n",
    "* 1) **Changing neighborhood:** A property with a changing neighborhood is simply assigned its modal neighborhood. \n",
    "* 2) **No neighborhood assigned:** A property without a reported neighborhood is assigned the neighborhood of the closest property that has a neighborhood reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding appropriate neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total listings:\n",
      "418359\n",
      "-------------------------\n",
      "Active listings with neighborhood reported:\n",
      "140237\n",
      "-------------------------\n",
      "Active listings with no neighborhood reported:\n",
      "10201\n"
     ]
    }
   ],
   "source": [
    "print(\"Total listings:\")\n",
    "\n",
    "print(len(listings_df['neighbourhood'].astype('category')))\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Active listings with neighborhood reported:\")\n",
    "print(len(listings_df[(listings_df['List_month']==1) & (~listings_df['neighbourhood'].isna())]))\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Active listings with no neighborhood reported:\")\n",
    "print(len(listings_df[(listings_df['List_month']==1) & (listings_df['neighbourhood'].isna())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code replaces each listing's neighborhood with its modal neighborhood\n",
    "modal_neighs = listings_df.groupby('id')['neighbourhood'].agg(lambda x: stats.mode(x)[0][0])\n",
    "listings_df.loc[:, 'neighbourhood'] = modal_neighs[listings_df['id']].values\n",
    "\n",
    "# Creates a dummy for whether neighborhood was initially reported\n",
    "listings_df.loc[:, 'missing_neigh'] = (listings_df['neighbourhood'] == 0)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average the reported longitude and latitude\n",
    "The longitude and latitude of a given property sometimes changes due to anonymization of Airbnb exact location. We just average these longitudes and latitudes to determine a representative location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_avg_lat, id_avg_lon = listings_df.groupby('id')['latitude'].mean(), listings_df.groupby('id')['longitude'].mean()\n",
    "\n",
    "listings_df.loc[:,'avg_lat'] = np.array(id_avg_lat[(listings_df['id'].values)])\n",
    "listings_df.loc[:, 'avg_lon'] = np.array(id_avg_lon[(listings_df['id'].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>avg_lat</th>\n",
       "      <th>avg_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1324</td>\n",
       "      <td>67036</td>\n",
       "      <td>45.531952</td>\n",
       "      <td>-122.644825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2109</td>\n",
       "      <td>107177</td>\n",
       "      <td>45.496996</td>\n",
       "      <td>-122.745876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4516</td>\n",
       "      <td>246398</td>\n",
       "      <td>45.479189</td>\n",
       "      <td>-122.607044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5322</td>\n",
       "      <td>281285</td>\n",
       "      <td>45.532832</td>\n",
       "      <td>-122.705484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11027</td>\n",
       "      <td>668224</td>\n",
       "      <td>45.532556</td>\n",
       "      <td>-122.777067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id    avg_lat     avg_lon\n",
       "0   1324   67036  45.531952 -122.644825\n",
       "1   2109  107177  45.496996 -122.745876\n",
       "2   4516  246398  45.479189 -122.607044\n",
       "3   5322  281285  45.532832 -122.705484\n",
       "4  11027  668224  45.532556 -122.777067"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set-up a dataframe of all of the listings missing a neighborhood\n",
    "missing_neigh = listings_df[(listings_df['List_month'] == 1) & (listings_df['neighbourhood'] == 0) & (~listings_df['latitude'].isna()) & (~listings_df['longitude'].isna())][['id', 'avg_lat', 'avg_lon']]\n",
    "missing_neigh = missing_neigh.drop_duplicates()\n",
    "missing_neigh = missing_neigh.sort_index()\n",
    "missing_neigh = missing_neigh.reset_index(drop = False)\n",
    "\n",
    "# Dataframe of all the listings, that are not missing a neighborhood\n",
    "not_missing_neigh = listings_df[(listings_df['List_month'] == 1) & (listings_df['neighbourhood'] != 0) & (~listings_df['latitude'].isna()) & (~listings_df['longitude'].isna())][['id', 'neighbourhood','avg_lat', 'avg_lon']]\n",
    "not_missing_neigh = not_missing_neigh.drop_duplicates()\n",
    "\n",
    "# Print first five rows of the missing neighborhood dataframe\n",
    "missing_neigh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_per_mi = 1.60934 #for distance conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate distance between two points\n",
    "    \"\"\"\n",
    "    return mpu.haversine_distance(point1, point2)\n",
    "\n",
    "def closest(data, this_point):\n",
    "    \"\"\"\n",
    "    Applies the distance function to each element in the data, \n",
    "    then returns the observation with the lowest distance.\n",
    "    \"\"\"\n",
    "    return min(data, key=lambda x: distance(this_point,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8474924451354475\n"
     ]
    }
   ],
   "source": [
    "# Test distance function\n",
    "\n",
    "print(distance((30.170165, -97.756954), (30.277500,-97.713975))/km_per_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_with_neigh = np.array(not_missing_neigh[['avg_lat', 'avg_lon']])\n",
    "coords_no_neigh = np.array(missing_neigh[['avg_lat', 'avg_lon']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mins to match neighborhoods:\n",
      "1.1291101535161336\n"
     ]
    }
   ],
   "source": [
    "# Identify neighborhoods for properties with no neighborhood assigned\n",
    "# NOTE: IF THIS HAS BEEN RUN ONCE, CAN COMMENT OUT AND JUST LOAD IN 'approximated_neighs.csv'\n",
    "\n",
    "neigh_timer = time.time()\n",
    "\n",
    "approx_neighs = []\n",
    "\n",
    "for i in coords_no_neigh:\n",
    "     approx_neighs.append(not_missing_neigh[(not_missing_neigh['avg_lat'] == closest(tuple(coords_with_neigh), tuple(i))[0]) & (not_missing_neigh['avg_lon'] == closest(tuple(coords_with_neigh), tuple(i))[1])]['neighbourhood'].values[0])\n",
    "\n",
    "missing_neigh['neighbourhood'] = approx_neighs\n",
    "\n",
    "# Save the approximate neighborhoods so this code doesn't need to be run again.\n",
    "missing_neigh.to_csv(city_abbrev + '_approximated_neighs.csv', index=False)\n",
    "\n",
    "time_to_match = time.time() - neigh_timer\n",
    "\n",
    "print(\"Mins to match neighborhoods:\")\n",
    "print(time_to_match/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If approximated_neighs.csv exists, can load in neighborhoods here.\n",
    "missing_neigh['neighbourhood'] = pd.read_csv(city_abbrev + '_approximated_neighs.csv')['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('mode.chained_assignment',None): # This just suppresses an innocous SettingWithCopy warning\n",
    "\n",
    "    listings_df.loc[:, 'neighbourhood'][missing_neigh['index'].values] = missing_neigh['neighbourhood'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all of the 0's with NaN's\n",
    "listings_df.loc[:, 'neighbourhood'] = listings_df['neighbourhood'].replace({0: np.nan})\n",
    "\n",
    "# Copy the neighborhood over the whole sample\n",
    "listings_df.loc[:,'neighbourhood'] = listings_df.groupby(['id'])['neighbourhood'].fillna(method='ffill', axis=0)\n",
    "listings_df.loc[:, 'neighbourhood'] = listings_df.groupby(['id'])['neighbourhood'].fillna(method='bfill', axis=0)\n",
    "\n",
    "# Create neighborhood dummies\n",
    "create_dummies('neighbourhood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 'Calendar Update' Formatting\n",
    "\n",
    "Here we calculate a numeric value for the days since an Airbnb listing's calendar has been updated. This offers a measure for how active the Airbnb property is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_update = listings_df['calendar_updated'].str.split(\" \", n=2, expand=True)\n",
    "cal_update.columns = ['count', 'units', 'numeric']\n",
    "\n",
    "cal_update = cal_update[['count', 'units']] # Drop the third column\n",
    "cal_update.loc[:, \"count\"] = cal_update['count'].replace({\"today\": 0, \"a\":1, \"yesterday\":0, \"never\":9999}).astype(float)\n",
    "cal_update.loc[:, \"units\"] = cal_update['units'].replace({\"days\": 1, \"None\":1, \"weeks\":7, \"months\":30, \"week\":7}).astype(float)\n",
    "cal_update.loc[:, 'days'] = cal_update['count']*cal_update['units']\n",
    "\n",
    "cal_update.loc[cal_update['count']==0.0, \"days\"] = 0.0\n",
    "cal_update.loc[cal_update['count']==9999, \"days\"] = 9999\n",
    "\n",
    "# Add the calendar update values to the dataframe\n",
    "listings_df.loc[:, 'days_since_calup'] = cal_update['days']\n",
    "del cal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing neighborhoods flag\n",
    "listings_df = listings_df.drop(columns=['missing_neigh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Additional variable creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flag month where a listing is first hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_host_ind = listings_df.groupby('id').List_month.idxmax()\n",
    "listings_df.loc[:, \"first_appearance\"] = (listings_df.index == first_host_ind[listings_df['id']]).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flag month where a listing is last hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df_list = listings_df[listings_df['List_month'] == 1]\n",
    "last = listings_df_list.groupby('id')['month'].last()\n",
    "\n",
    "listings_df.loc[:, 'last_app'] = (listings_df['month'].values == last[listings_df['id']].values).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cumulative listings for a given host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cumlists = listings_df.groupby(['host_id', 'month'])['first_appearance'].sum().unstack().cumsum(axis=1).stack().astype(int)\n",
    "host_cumlists.name = 'cum_sum'\n",
    "listings_df = listings_df.join(host_cumlists, on=['host_id', 'month'], rsuffix='_cumsum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate other summary statistics about host holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Host listings per month\n",
    "listings_df = listings_df.join(listings_df.groupby(['host_id', 'month'])['List_month'].sum(), on=['host_id', 'month'], rsuffix='_byhost_month')\n",
    "\n",
    "# Host overall listings over the dataset\n",
    "listings_df = listings_df.join(listings_df.groupby(['host_id'])['List_month'].sum(), on=['host_id'], rsuffix='_host_overall')\n",
    "\n",
    "# Total times a given property is listed\n",
    "listings_df = listings_df.join(listings_df.groupby(['id'])['List_month'].sum(), on=['id'], rsuffix='_id_overall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify hotels in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df.loc[:, 'hotel_dum'] = np.array((listings_df['property_type'] == \"Boutique hotel\") |\n",
    "                                  (listings_df['property_type'] == \"Bed and breakfast\") | \n",
    "                                  (listings_df['property_type'] == \"Boutique hotel\") | \n",
    "                                  (listings_df['property_type'] == \"Aparthotel\")| \n",
    "                                  (listings_df['property_type'] == \"Hotel\")| \n",
    "                                  (listings_df['property_type'] == \"Resort\")| \n",
    "                                  (listings_df['property_type'] == \"Serviced apartment\") )*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure for an entrant to the Airbnb platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preliminary measure for an entrant Airbnb listing.\n",
    "listings_df.loc[:,\"entrant\"] =  np.array((listings_df['first_appearance'] == 1) &\n",
    "                                (listings_df['days_since_first_rev'] < 30 ) & \n",
    "                                (listings_df['number_of_reviews'] < 10 ))*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate listings per neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>month</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>List_month_byneigh</th>\n",
       "      <th>List_month_lag_byneigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11359</th>\n",
       "      <td>681972</td>\n",
       "      <td>0</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19388</th>\n",
       "      <td>1125125</td>\n",
       "      <td>0</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19425</th>\n",
       "      <td>1128026</td>\n",
       "      <td>0</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22496</th>\n",
       "      <td>1268272</td>\n",
       "      <td>0</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24827</th>\n",
       "      <td>1420478</td>\n",
       "      <td>0</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406518</th>\n",
       "      <td>29884092</td>\n",
       "      <td>36</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>93</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407628</th>\n",
       "      <td>30010653</td>\n",
       "      <td>36</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>93</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408294</th>\n",
       "      <td>30085303</td>\n",
       "      <td>36</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>93</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413104</th>\n",
       "      <td>31043503</td>\n",
       "      <td>36</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>93</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414325</th>\n",
       "      <td>31291509</td>\n",
       "      <td>36</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>93</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418359 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  month neighbourhood  List_month_byneigh  \\\n",
       "11359     681972      0       Alameda                  15   \n",
       "19388    1125125      0       Alameda                  15   \n",
       "19425    1128026      0       Alameda                  15   \n",
       "22496    1268272      0       Alameda                  15   \n",
       "24827    1420478      0       Alameda                  15   \n",
       "...          ...    ...           ...                 ...   \n",
       "406518  29884092     36     Woodstock                  93   \n",
       "407628  30010653     36     Woodstock                  93   \n",
       "408294  30085303     36     Woodstock                  93   \n",
       "413104  31043503     36     Woodstock                  93   \n",
       "414325  31291509     36     Woodstock                  93   \n",
       "\n",
       "        List_month_lag_byneigh  \n",
       "11359                      NaN  \n",
       "19388                      NaN  \n",
       "19425                      NaN  \n",
       "22496                      NaN  \n",
       "24827                      NaN  \n",
       "...                        ...  \n",
       "406518                    90.0  \n",
       "407628                    90.0  \n",
       "408294                    90.0  \n",
       "413104                    90.0  \n",
       "414325                    90.0  \n",
       "\n",
       "[418359 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of listings in a neighborhood on the Airbnb platform for a given month\n",
    "listings_df = listings_df.join(listings_df.groupby(['neighbourhood', 'month'])['List_month'].sum(), \n",
    "             on=['neighbourhood', 'month'], rsuffix='_byneigh')\n",
    "\n",
    "# Calculate the lagged number of listings in a neighborhood on the Airbnb platform for a given month\n",
    "listings_df = listings_df.join(listings_df.sort_values(by=['neighbourhood', 'month']).groupby(['neighbourhood', 'month'])['List_month'].sum().shift(1), \n",
    "             on=['neighbourhood', 'month'], rsuffix='_lag_byneigh')\n",
    "\n",
    "listings_df.loc[:,'List_month_lag_byneigh'] =  listings_df['List_month_lag_byneigh'].mask(listings_df['month'] == 3, np.nan)\n",
    "\n",
    "listings_df.sort_values(by=['neighbourhood', 'month'])[['id', 'month', 'neighbourhood', 'List_month_byneigh', 'List_month_lag_byneigh']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Creating drop criteria for observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 0-valued drop indicator. This will be replaced with 1 \n",
    "# whenever certain conditions are satisfied\n",
    "\n",
    "listings_df.loc[:, 'drop_indicator'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop criteria 1: Property *never* earns a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum difference in reviews by property\n",
    "max_NORdiff = listings_df.groupby('id')['NOR_diff'].max()\n",
    "listings_df.loc[:, 'max_NORdiff'] = max_NORdiff[listings_df['id']].values\n",
    "\n",
    "no_revs_ind = (listings_df['max_NORdiff'] == 0).values*1\n",
    "listings_df.loc[:, 'drop_indicator'] = listings_df['drop_indicator'].replace({ 0: no_revs_ind})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Drop criteria 2: Property price is below 0.1 percentile or above 99.9 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_01per = listings_df.price.quantile(.001)\n",
    "price_999per = listings_df.price.quantile(.999)\n",
    "\n",
    "low_price = (listings_df.groupby('id')['price'].min()[listings_df['id']].values < price_01per)*1\n",
    "high_price = (listings_df.groupby('id')['price'].min()[listings_df['id']].values > price_999per)*1\n",
    "\n",
    "listings_df.loc[:, 'drop_indicator'] = listings_df['drop_indicator'].replace({ 0: low_price})\n",
    "listings_df.loc[:, 'drop_indicator'] = listings_df['drop_indicator'].replace({ 0: high_price})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Drop criteria 3: Property *never* lists a day of availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_avail = (listings_df.groupby('id')['availability_365'].max()[listings_df['id']].values == 0)*1\n",
    "listings_df.loc[:, 'drop_indicator'] = listings_df['drop_indicator'].replace({ 0: never_avail})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop criteria 4: Minimum nights is 30 days or more (no longer a short-term rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_term_rental = (listings_df.groupby(['id'])['minimum_nights'].min()[listings_df['id']].values >= 30)*1\n",
    "listings_df.loc[:, 'drop_indicator'] = listings_df['drop_indicator'].replace({ 0: long_term_rental})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Drop criteria 5: Hotel indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_ind = (listings_df.groupby(['id'])['hotel_dum'].max()[listings_df['id']].values == 1)*1\n",
    "listings_df.loc[:, 'drop_indicator'] = listings_df['drop_indicator'].replace({ 0: hotel_ind})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique properties flagged for drop:\n",
      "2792\n",
      "Unique properties not flagged for drop:\n",
      "8515\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique properties flagged for drop:\")\n",
    "print(listings_df.groupby('id')['drop_indicator'].max().values.sum())\n",
    "\n",
    "print(\"Unique properties not flagged for drop:\")\n",
    "print((1 - listings_df.groupby('id')['drop_indicator'].max().values).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# -- Save to compressed csv --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(csv_save_path)\n",
    "listings_df.to_csv(city_abbrev + '_1stStageClean.csv.gz', compression='gzip', index=False, date_format='%Y-%m-%d %H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
